{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#Coding\n",
    "\n",
    "The performance metrics of the custom network and the pretrained network are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset mean: [0.4541, 0.4541, 0.4541]\n",
      "Dataset std: [0.2522, 0.2522, 0.2522]\n",
      "Found 1500 images belonging to 15 classes.\n",
      "Found 2985 images belonging to 15 classes.\n",
      "Model: \"your_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             multiple                  1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  multiple                 0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           multiple                  73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           multiple                  295168    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           multiple                  590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  327682048 \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  4196352   \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  30735     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332,870,031\n",
      "Trainable params: 332,870,031\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Done setting up image labeling logger.\n",
      "Epoch 1/50\n",
      "\n",
      " 1/15 [=>............................] - ETA: 4:46 - loss: 5.1958 - sparse_categorical_accuracy: 0.1000\n",
      " 2/15 [===>..........................] - ETA: 6s - loss: 5.9057 - sparse_categorical_accuracy: 0.0950  \n",
      " 3/15 [=====>........................] - ETA: 8s - loss: 5.9009 - sparse_categorical_accuracy: 0.0967\n",
      " 4/15 [=======>......................] - ETA: 7s - loss: 5.6638 - sparse_categorical_accuracy: 0.0950\n",
      " 5/15 [=========>....................] - ETA: 6s - loss: 5.6245 - sparse_categorical_accuracy: 0.0900\n",
      " 6/15 [===========>..................] - ETA: 5s - loss: 5.7564 - sparse_categorical_accuracy: 0.0917\n",
      " 7/15 [=============>................] - ETA: 5s - loss: 5.6956 - sparse_categorical_accuracy: 0.0929\n",
      " 8/15 [===============>..............] - ETA: 4s - loss: 5.5077 - sparse_categorical_accuracy: 0.0962\n",
      " 9/15 [=================>............] - ETA: 3s - loss: 5.4096 - sparse_categorical_accuracy: 0.0956\n",
      "10/15 [===================>..........] - ETA: 3s - loss: 5.3694 - sparse_categorical_accuracy: 0.1050\n",
      "11/15 [=====================>........] - ETA: 2s - loss: 5.3382 - sparse_categorical_accuracy: 0.1055\n",
      "12/15 [=======================>......] - ETA: 1s - loss: 5.2613 - sparse_categorical_accuracy: 0.1050\n",
      "13/15 [=========================>....] - ETA: 1s - loss: 5.2167 - sparse_categorical_accuracy: 0.1046\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 5.1940 - sparse_categorical_accuracy: 0.1093\n",
      "15/15 [==============================] - ETA: 0s - loss: 5.2008 - sparse_categorical_accuracy: 0.1133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1531s vs `on_train_batch_end` time: 0.4162s). Check your callbacks.\n",
      "error: Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice\n",
      "error: Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice\n",
      "error: Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice\n",
      "error: Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice\n",
      "error: Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice\n",
      "error: Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice\n",
      "error: Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice\n",
      "error: Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice\n",
      "error: Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice\n",
      "error: Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice\n",
      "error: Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice\n",
      "error: Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice\n",
      "error: Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Pan Lab\\Documents\\SYDE671ASS4\\Code\\run.py\", line 141, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\Pan Lab\\Documents\\SYDE671ASS4\\Code\\run.py\", line 136, in main\n",
      "    train(model, datasets, checkpoint_path)\n",
      "  File \"C:\\Users\\Pan Lab\\Documents\\SYDE671ASS4\\Code\\run.py\", line 83, in train\n",
      "    model.fit(\n",
      "  File \"C:\\Users\\Pan Lab\\Documents\\SYDE671ASS4\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Pan Lab\\Documents\\SYDE671ASS4\\Code\\tensorboard_utils.py\", line 38, in on_epoch_end\n",
      "    self.log_image_labels(epoch, logs)\n",
      "  File \"C:\\Users\\Pan Lab\\Documents\\SYDE671ASS4\\Code\\tensorboard_utils.py\", line 88, in log_image_labels\n",
      "    tf.summary.image(\"Image Label Predictions\", figure_img, step=epoch_num)\n",
      "  File \"C:\\Users\\Pan Lab\\Documents\\SYDE671ASS4\\venv\\lib\\site-packages\\tensorboard\\plugins\\image\\summary_v2.py\", line 140, in image\n",
      "    return tf.summary.write(\n",
      "tensorflow.python.framework.errors_impl.UnknownError: {{function_node __wrapped__FloorMod_device_/job:localhost/replica:0/task:0/device:GPU:0}} JIT compilation failed. [Op:FloorMod]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "The architecture of the custom network was largely inspired by the VGG-net, where blocks of convolutional layers and max pooling layers are performed sequentially. The convolutional layers are doubled in size after each block before being halved before the 2 final dense layers and classification layer. Many convolutional layers have the added advantage of reducing the total amount of model parameters by downsampling the size of the image. A dropout rate of 0.2 is performed for every dense layer in order to prevent overfitting.\n",
    "\n",
    "In order to apply transfer learning to the pre-trained VGG-net, all of the pretrained weights are frozen in order to leverage the learned information. Layers are then added at the end of the network in order to learn the new dataset. It was found that in order to get good performance, the classification head had to have an architecture slightly more complex than a simple dense classification layer. In this case, the architecture is some downsampling convolutional and maxpooling blocks, followed by 2 dense layers before a final classification layer. Once again, a dropout rate of 0.2 is selected for each dense layer to rpevent overfitting. This architecture achieved a peak validation accuracy of 90.32% after 37 epochs, and was trained for a total of 50.\n",
    "\n",
    "For training of both models, a batch size of 100 was used in order to decrease runtime. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "25f0b89e1a3e25bd0632555529b2ddfdf881086d3f9a8149ec33ebcae9ccaa30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
